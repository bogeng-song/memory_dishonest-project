{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import Workbook\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.rcParams['axes.labelcolor'] = 'black'\n",
    "plt.rcParams['xtick.color'] = 'black'\n",
    "plt.rcParams['ytick.color'] = 'black'\n",
    "plt.rcParams['legend.facecolor'] = 'white' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_to_excel(data_dict, filename):\n",
    "    workbook = Workbook()\n",
    "\n",
    "    worksheet = workbook.active\n",
    "\n",
    "    headers = list(data_dict.keys())\n",
    "    worksheet.append(headers)\n",
    "\n",
    "    values = list(data_dict.values())\n",
    "    worksheet.append(values)\n",
    "\n",
    "    workbook.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reward = pd.read_excel('reward_quest.xlsx')\n",
    "df_punish = pd.read_excel('punishment_quest.xlsx')\n",
    "df_mixed = pd.read_excel('mixed_quest.xlsx')\n",
    "df_p_memory1 = pd.read_csv('punishment_memory_summary.csv')\n",
    "df_r_memory1 = pd.read_csv('reward_memory_summary.csv')\n",
    "df_m_memory1 = pd.read_csv('mixed_memory_summary.csv')\n",
    "df_hddm_m = pd.read_csv('mixed_hddm_stats.csv')\n",
    "df_hddm_r = pd.read_csv('reward_hddm_stats.csv')\n",
    "df_hddm_p = pd.read_csv('punish_hddm_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_memory1['rt'] = pd.to_numeric(df_p_memory1['rt'], errors='coerce')\n",
    "df_p_memory1 = df_p_memory1.dropna(subset=['rt'])\n",
    "df_r_memory1['rt'] = pd.to_numeric(df_r_memory1['rt'], errors='coerce')\n",
    "df_r_memory1 = df_r_memory1.dropna(subset=['rt'])\n",
    "df_m_memory1['rt'] = pd.to_numeric(df_m_memory1['rt'], errors='coerce')\n",
    "df_m_memory1 = df_m_memory1.dropna(subset=['rt'])\n",
    "\n",
    "df_m_memory1['meta'] = 1 - (df_m_memory1['accuracy'] - df_m_memory1['confidence']/100)**2\n",
    "df_r_memory1['meta'] = 1 - (df_r_memory1['accuracy'] - df_r_memory1['confidence']/100)**2\n",
    "df_p_memory1['meta'] = 1 - (df_p_memory1['accuracy'] - df_p_memory1['confidence']/100)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_memory = df_r_memory1.groupby(['subject_nr', 'menu', 'stage', 'condition']).agg(\n",
    "    accuracy=('accuracy', 'mean'),\n",
    "    confidence=('confidence', 'mean'),\n",
    "    meta=('meta', 'mean'),\n",
    "    AUC=('AUC', 'mean'),\n",
    "    rt=('rt', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "df_m_memory = df_m_memory1.groupby(['subject_nr', 'menu', 'stage', 'condition']).agg(\n",
    "    accuracy=('accuracy', 'mean'),\n",
    "    confidence=('confidence', 'mean'),\n",
    "    meta=('meta', 'mean'),\n",
    "    AUC=('AUC', 'mean'),\n",
    "    rt=('rt', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "df_p_memory = df_p_memory1.groupby(['subject_nr', 'menu', 'stage', 'condition']).agg(\n",
    "    accuracy=('accuracy', 'mean'),\n",
    "    confidence=('confidence', 'mean'),\n",
    "    meta=('meta', 'mean'),\n",
    "    AUC=('AUC', 'mean'),\n",
    "    rt=('rt', 'mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list_reward = df_r_memory['subject_nr'].unique()\n",
    "cond_list_reward = df_r_memory['condition'].unique()\n",
    "stage_list_reward = df_r_memory['stage'].unique()\n",
    "\n",
    "sub_list_punishment = df_p_memory['subject_nr'].unique()\n",
    "cond_list_punishment = df_p_memory['condition'].unique()\n",
    "stage_list_punishment = df_p_memory['stage'].unique()\n",
    "\n",
    "sub_list_mixed = df_m_memory['subject_nr'].unique()\n",
    "cond_list_mixed= df_m_memory['condition'].unique()\n",
    "stage_list_mixed= df_m_memory['stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hddm_m.rename(columns={'Unnamed: 0':'V1'}, inplace=True)\n",
    "df_hddm_r.rename(columns={'Unnamed: 0':'V1'}, inplace=True)\n",
    "df_hddm_p.rename(columns={'Unnamed: 0':'V1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hddm_para(ddm_results,subList):\n",
    "    v_former_diff = ddm_results[ddm_results['V1'].str.contains(\"v_former_diff_subj\")][['mean', 'V1']].reset_index(drop=True)\n",
    "    v_ses = ddm_results[ddm_results['V1'].str.contains(\"v_ses_subj\")][['mean', 'V1']].reset_index(drop=True)\n",
    "    v_former_diff_ses = ddm_results[ddm_results['V1'].str.contains(\"v_former_diff:ses_subj\")][['mean', 'V1']].reset_index(drop=True)\n",
    "    v_diff = ddm_results[ddm_results['V1'].str.contains(\"v_diff_subj\")][['mean', 'V1']].reset_index(drop=True)\n",
    "    v_diff_ses = ddm_results[ddm_results['V1'].str.contains(\"v_diff:ses_subj\")][['mean', 'V1']].reset_index(drop=True)\n",
    "    a_ses = ddm_results[ddm_results['V1'].str.contains(\"a_ses_subj\")][['mean', 'V1']].reset_index(drop=True)\n",
    "    z_ses = ddm_results[ddm_results['V1'].str.contains(\"z_ses_subj\")][['mean', 'V1']].reset_index(drop=True)\n",
    "\n",
    "    # Combine the data\n",
    "    ddm_params = pd.concat([\n",
    "        v_former_diff[['mean']], \n",
    "        v_ses[['mean']], \n",
    "        v_former_diff_ses[['mean']], \n",
    "        v_diff[['mean']], \n",
    "        v_diff_ses[['mean']], \n",
    "        a_ses[['mean']], \n",
    "        z_ses[['mean']]\n",
    "    ], axis=1)\n",
    "\n",
    "    ddm_params.columns = ['v_former_diff', 'v_ses', 'v_former_diff_ses', 'v_diff', 'v_diff_ses', 'a_ses', 'z_ses']\n",
    "\n",
    "\n",
    "    ddm_params['subjno'] = subList\n",
    "    \n",
    "    return ddm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm_para_mixed = get_hddm_para(df_hddm_m,sub_list_mixed)\n",
    "hddm_para_reward = get_hddm_para(df_hddm_r,sub_list_reward)\n",
    "hddm_para_punish = get_hddm_para(df_hddm_p,sub_list_punishment)\n",
    "parameter_list = hddm_para_mixed.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_list_p = df_punish.columns.tolist()\n",
    "col_name_list_m = df_mixed.columns.tolist()\n",
    "col_name_list_r = df_reward.columns.tolist()\n",
    "reward_emotion_list = [20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42]\n",
    "punish_emotion_list = [26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48]\n",
    "mixed_emotion_list = [26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the matrix with the emotion, lie rate and hddm parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = ['#70309f','#e7b13e','#2a74a3','#c66236','#00FFFF']\n",
    "emotion_list = ['Interested','Distressed','Excited','Upset','Strong','Guilty','Scared','Hostile','Enthusiastic','Proud','Irritable','Alert','Ashamed','Inspired','Nervous','Determined','Attentive','Jittery','Active','Afraid','Positive_Sum','Negative_Sum','Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_punish = np.zeros([len(sub_list_punishment), len(emotion_list)])\n",
    "\n",
    "for i in range(len(sub_list_punishment)):\n",
    "    for j in range(len(emotion_list)):\n",
    "        col_nn = col_name_list_p[punish_emotion_list[j]]\n",
    "        data_punish[i,j] = df_punish[col_nn][df_punish.iloc[:, 6] == sub_list_punishment[i]].to_numpy()[0]\n",
    "        \n",
    "data_reward = np.zeros([len(sub_list_reward), len(emotion_list)])\n",
    "\n",
    "for i in range(len(sub_list_reward)):\n",
    "    for j in range(len(emotion_list)):\n",
    "        col_nn = col_name_list_p[punish_emotion_list[j]]\n",
    "        data_reward[i,j] = df_reward[col_nn][df_reward.iloc[:, 1] == sub_list_reward[i]].to_numpy()[0] \n",
    "        \n",
    "data_mixed = np.zeros([len(sub_list_mixed), len(emotion_list)])\n",
    "\n",
    "for i in range(len(sub_list_mixed)):\n",
    "    for j in range(len(emotion_list)):\n",
    "        col_nn = col_name_list_p[punish_emotion_list[j]]\n",
    "        data_mixed[i,j] = df_mixed[col_nn][df_mixed.iloc[:, 6] == sub_list_mixed[i]].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = ['Interested','Distressed','Excited','Upset','Strong','Guilty','Scared','Hostile','Enthusiastic','Proud','Irritable','Alert','Ashamed','Inspired','Nervous','Determined','Attentive','Jittery','Active','Afraid','Pos','Neg','Total']\n",
    "df_punish_emo = pd.DataFrame(data_punish, columns=column_list)\n",
    "df_reward_emo = pd.DataFrame(data_reward, columns=column_list)\n",
    "df_mixed_emo = pd.DataFrame(data_mixed, columns=column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_punish = pd.concat([df_punish_emo, hddm_para_punish], axis=1)\n",
    "combined_df_punish = combined_df_punish.drop(columns='subjno')\n",
    "\n",
    "combined_df_reward = pd.concat([df_reward_emo, hddm_para_reward], axis=1)\n",
    "combined_df_reward = combined_df_reward.drop(columns='subjno')\n",
    "\n",
    "combined_df_mixed = pd.concat([df_mixed_emo, hddm_para_mixed], axis=1)\n",
    "combined_df_mixed = combined_df_mixed.drop(columns='subjno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = combined_df_punish.corr()\n",
    "p_matrix = np.zeros_like(corr)\n",
    "for i in range(len(corr)):\n",
    "    for j in range(len(corr)):\n",
    "        _, p_matrix[i, j] = pearsonr(combined_df_punish.iloc[:, i], combined_df_punish.iloc[:, j])\n",
    "\n",
    "alpha = 0.05\n",
    "mask_significant = p_matrix >= alpha\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.figure(figsize=(10, 8))\n",
    "custom_colors = [\"blue\", \"white\", \"red\"]\n",
    "sns.heatmap(corr, mask=mask | mask_significant)\n",
    "plt.title('Correlation Matrix with punishment hddm result and emotion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_matrix_p = pd.DataFrame(p_matrix, index=corr.index, columns=corr.columns)\n",
    "df_pvalue_p = p_value_matrix_p.applymap(lambda x: round(x, 4))\n",
    "corr_value_p = combined_df_punish.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = combined_df_reward.corr()\n",
    "p_matrix = np.zeros_like(corr)\n",
    "for i in range(len(corr)):\n",
    "    for j in range(len(corr)):\n",
    "        _, p_matrix[i, j] = pearsonr(combined_df_reward.iloc[:, i], combined_df_reward.iloc[:, j])\n",
    "\n",
    "alpha = 0.05\n",
    "mask_significant = p_matrix >= alpha\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.figure(figsize=(10, 8))\n",
    "custom_colors = [\"blue\", \"white\", \"red\"]\n",
    "sns.heatmap(corr, mask=mask | mask_significant)\n",
    "plt.title('Correlation Matrix with reward hddm result and emotion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_matrix_r = pd.DataFrame(p_matrix, index=corr.index, columns=corr.columns)\n",
    "df_pvalue_r = p_value_matrix_r.applymap(lambda x: round(x, 4))\n",
    "corr_value_r = combined_df_reward.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = combined_df_mixed.corr()\n",
    "p_matrix = np.zeros_like(corr)\n",
    "for i in range(len(corr)):\n",
    "    for j in range(len(corr)):\n",
    "        _, p_matrix[i, j] = pearsonr(combined_df_mixed.iloc[:, i], combined_df_mixed.iloc[:, j])\n",
    "\n",
    "alpha = 0.05\n",
    "mask_significant = p_matrix >= alpha\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.figure(figsize=(10, 8))\n",
    "custom_colors = [\"blue\", \"white\", \"red\"]\n",
    "sns.heatmap(corr, mask=mask | mask_significant)\n",
    "plt.title('Correlation Matrix with mixed hddm result and emotion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_matrix_m = pd.DataFrame(p_matrix, index=corr.index, columns=corr.columns)\n",
    "df_pvalue_m = p_value_matrix_m.applymap(lambda x: round(x, 4))\n",
    "corr_value_m = combined_df_mixed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"hddm_pvalue.xlsx\"\n",
    "\n",
    "# Save DataFrames to different sheets\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    df_pvalue_r.to_excel(writer, sheet_name='reward', index=False)\n",
    "    df_pvalue_p.to_excel(writer, sheet_name='punish', index=False)\n",
    "    df_pvalue_m.to_excel(writer, sheet_name='mixed', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"hddm_corr_value.xlsx\"\n",
    "\n",
    "# Save DataFrames to different sheets\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    corr_value_r.to_excel(writer, sheet_name='reward', index=False)\n",
    "    corr_value_p.to_excel(writer, sheet_name='punish', index=False)\n",
    "    corr_value_m.to_excel(writer, sheet_name='mixed', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the correlation for the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(df, col1, col2):\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=df, x=col1, y=col2, color='blue', alpha=0.6, s=50)\n",
    "    sns.regplot(data=df, x=col1, y=col2, scatter=False, color='red', line_kws={\"linewidth\": 2})\n",
    "    \n",
    "    plt.title(f'Correlation between {col1} and {col2}', fontsize=16)\n",
    "    plt.xlabel(col1, fontsize=12)\n",
    "    plt.ylabel(col2, fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(combined_df_reward, 'Interested', 'v_diff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
